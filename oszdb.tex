\documentclass[12pt]{article}

\usepackage{geometry}
\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage{polski}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{acronym}
\usepackage{fancyhdr}

\hypersetup{
  linkbordercolor={1 1 1},
  urlbordercolor={1 1 1},
  colorlinks=false
}

\pagestyle{fancy}
\cfoot{}
\rfoot{\thepage}

\author{Michał Bugno \and Antek Piechnik}
\title{Wykłady z OSZBD}

\begin{document}
\maketitle
\tableofcontents
\newpage

\section{Ten plik}
Plik to zapis wykładów dra Roberta Marcjana na Akademii~Górniczo--Hutniczej
w~Krakowie na kierunku Informatyka.
\begin{itemize}
\item inicjatywa: msq (\url{michal.bugno<at>gmail.com})
\item pomoc: tph (\url{antek.piechnik<at>gmail.com}).
\item źródła można znaleźć w repozytorium \href{http://git.or.cz/}{Git--a}
      pod adresem:\\ \url{http://github.com/michalbugno/wyklady-oszdb/}
\end{itemize}

\section{Wstęp}
\subsection{Literatura}
\begin{itemize}
\item Silberschatz ``Database System Concepts``
\item Garcia-Molina, Ullman, Widom ``Database systems The Complete Book``
\item (!)Garcia-Molina, Ullman, Widom ``Implementacja Systemow Baz Danych``
\item Ramakrishan, Gecherke ``Database Managment Systems``
\item Date ``Wprowadzenie Do Baz Danych`` (uzupełniająca, raczej nie)
\item Celko ``SQL zaawansowane techniki programowania``
\end{itemize}

\subsection{Omawiane bazy danych}
\subsubsection{Komercyjne}
\begin{itemize}
\item Oracle
\item IBM INFORMIX
\item IBM DB2
\item MS SQL
\item Sybase
\end{itemize}

\subsubsection{Darmowe}
\begin{itemize}
\item PostgreSQL
\item MySQL
\end{itemize}

\subsection{Linki}
\begin{itemize}
\item \url{http://www.sqlservercentral.com}
\item \url{http://www.databaseweekly.com}
\item \url{http://www.oracle.com/oramag/index.html}
\item \url{http://www.db2mag.com}
\item \url{http://www.iiug.org}
\end{itemize}

\subsection{Plan}
\subsubsection{Semestr zimowy}
\begin{enumerate}
\item \ac{SZBD}
\begin{itemize}
\item pamięć, procesy, dysk
\item moduły funkcjonalne \ac{SZBD}, architektura klient/serwer
\end{itemize}
\item Fizyczna struktura danych
\begin{itemize}
\item struktura fizyczna zbiorów
\item metody przechowywania danych, organizacja dysków, \acs{RAID}
\item fragmentacja/partycjonowanie
\end{itemize}
\item Metody dostępu do danych, indeksowanie
\begin{itemize}
\item dostęp sekwencyjny
\item indeksy, \ac{B--Tree}, hash, bitmap, siatkowe (struktury wielowymiarowe)
\end{itemize}
\item Przetwarzanie transakcyjne
\begin{itemize}
\item pojęcie transakcji
\item \ac{ACID}
\end{itemize}
\item Metody realizacji przetwarzania transakcyjnego
\begin{itemize}
\item ACD
\end{itemize}
\item Równoczesny dostęp do danych
\begin{itemize}
\item poziomy izolacji
\item metody zarządzania równoczesnym dostępem
\item blokady, wielowersyjność
\end{itemize}
\item Realizacja operacji, optymalizacja
\begin{itemize}
\item algebra relacji
\item SQL, PL/SQL i podobne
\item sposoby realizacji operacji (SELECT, JOIN itp.)
\end{itemize}
\item Replikacja danych
\begin{itemize}
\item metody replikacji danych
\item synchronizacja danych
\end{itemize}
\item Bezpieczeństwo
\begin{itemize}
\item integralność, transakcje
\item archiwizacja, odtwarzanie
\item fault tolerance (\acs{RAID}, klastry, replikacja)
\end{itemize}
\item Administracja i optymalizacja wydajności serwera
\begin{itemize}
\item konfiguracja (specyficzne cechy SZBD)
\item strojenie
\end{itemize}
\item Przetwarzanie informacji przestrzennych, GIS
\begin{itemize}
\item metody, algorytmy, struktury danych
\item Oracle spatial, DB2, INFORMIX, MS SQL 2008
\end{itemize}
\item Przykłady SZBD
\begin{itemize}
\item IBM/Informix
\item IBM/DB2
\item Oracle
\item MSSQL Server
\end{itemize}
\end{enumerate}

\subsubsection{Semestr letni}
\begin{enumerate}
\item Hurtownie danych
\item Analiza danych
\item Exploracja danych
\end{enumerate}

\subsection{Laboratoria}
\begin{itemize}
\item podział na grupy na 2 semestry
\item Prowadzący
\begin{itemize}
\item Anna Zygmunt (pon. 11.oo - 12.3o, pt. 15.3o - 17.oo)
\item Robert Marcjan (pon. 9.3o - 11.oo)
\item Leszek Siwik (pt. 15.3o - 17.oo)
\end{itemize}
\end{itemize}

%* modele danych
%* szbd
%* architektury systemow baz danych
%* budowa wewnetrzna

\begin{description}
\item[Model danych] zestaw pojęć używanych do opisu danych
\end{description}

Modele danych:
\begin{itemize}
\item związków encji
\item sieciowy
\item hierarchiczny
\item relacyjny (mocna teoria (algebra relacji), udany, prosty)
\item obiektowy (nie tak wydajny jak relacyjny)
\item obiektowo-relacyjny
\end{itemize}

\section{Relacyjny model danych}
\subsection{Cechy}

\begin{itemize}
\item relacje, krotki, atrybuty
\item tabele, wiersze, kolumny
\item algebra relacji (prosta, przejrzysta)
\begin{itemize}
\item wejście: relacja1, relacja2 ..., wyjście: nowa relacja
\item operacje: selekcja, projekcja, złączenie (join), suma, różnica, przecięcie etc.
\end{itemize}
\item język \acs{SQL}
\end{itemize}

\subsection{Niezależność}
\begin{itemize}
\item możliwość modyfikacji definicji (schematu) na danym poziomie bez konieczności zmian na wyższym poziomie
   (poziom fizyczny, logiczny, prezentacji)
\item aplikacje są niezależne od tego jak dane są strukturalizowane i przechowywane
\end{itemize}

\subsection{Architektury}
\begin{itemize}
\item  mainframe
\item  file sharing, \acs{ISAM} (na plikach)
\item  client-server (klient nie ``dotyka`` serwera)
\item  architektury wielowarstwowe (3 warstwowe)
\item  architektury rozproszone
\begin{itemize}
\item  rozproszenie danych
\item powielanie (replikacja) danych
\item transakcje rozproszone
\end{itemize}
\item  architektury równoległe (w tym widzi się skok wydajności, dotychczasowe rozwiązania są już
   bardzo dobrze zoptymalizowane)
\end{itemize}

\subsection{Client--server}
\begin{itemize}
\item operacje ``klienta``
\item operacje ``serwera``
\item \ac{SQL}
\item stored procedures -- każdy ma własny język, nie ma zgodności (zmienne, pętle, nie ma struktur danych)
\item \ac{SQL} + możliwość wykonania programu na serwerze (SUM(kolumna) vs SELECT * a potem sumuj, programy w Java, C)
\end{itemize}

\subsection{Dlaczego \acs{SZBD}?}
\begin{itemize}
\item redundancja danych
\item spójność danych (dlaczego nie tylko w aplikacji? bo z reguły \ac{SZBD} żyje DŁUŻEJ niż aplikacja)
\item równoczesny dostęp do danych (nie trzeba przejmować się równoczesny dostępem)
\item transakcje (\ac{ACID})
\item bezpieczeństwo danych
\begin{itemize}
\item ochrona przed niepowołanym dostępem (bardzo dokładna kontrola np. konkretne kolumny)
\item odporność na awarię
\end{itemize}
\end{itemize}
Przetwarzanie powinno być \emph{efektywne}.

\section{Pamięć, dyski}
W \ac{SZBD} dane przechowywane są na dyskach. Ma to znaczenie przy ich projektowaniu.

\subsection{Hierarchia szybkości}
\begin{enumerate}
\item cache (najszybszy)
\item main memory
\item flash memory
\item magnetic disk
\item optical disk
\item magnetic tapes (najwolniejszy)
\end{enumerate}

\subsection{Podstawowe operacje}
\begin{description}
\item[READ] transfer z dysku do RAM
\item[WRITE] zapis z RAM na dysk
\end{description}
Te operacje są kosztowne w porównaniu do operacji w pamięci

\subsection{Komponenty tworzące \ac{SZBD}}
\begin{itemize}
\item dysk
\begin{itemize}
\item struktury przechowujące dane
\item struktury przechowujące opis danych
\item struktury zapewniające przetwarzanie transakcyjne
\item struktury zapewniające bezpieczeństwo
\end{itemize}
\item procesy
\begin{itemize}
\item operacje związane z funkcjonowaniem serwera
\item operacje wykonywane ``na zlecenie`` aplikacji klienckich
\end{itemize}
\item pamięć
\begin{itemize}
\item pula buforów
\item struktury kontrolne
\end{itemize}
\end{itemize}

Typowy system ma dużo więcej danych na dysku niż może przechowywać w pamięci.

\subsection{Sposoby zabezpieczeń}
\subsubsection{\acs{RAID}}
\begin{itemize}
\item backup danych, backup logów (raz na jakiś czas zapisujemy dane, ciągle backupujemy logi)
\item w przypadku awarii restore danych a potem wykonujemy logi od ostatniego dobrego backupu
\end{itemize}

\subsubsection{Replikacja}
\begin{itemize}
\item zabezpieczenie przed utratą wszystkiego (serwer wykonuje log i przesyła go gdzieś indziej, do innego serwera)
\item przybliżenie użytkownikowi danych (coraz mniejsza rola tej funkcji, przepustowość sieci rośnie)
\end{itemize}

\subsubsection{Struktury dyskowe}
\begin{itemize}
\item czas dostępu do dysku jest bardzo wolny
\item operujemy na dużych zbiorach danych
\item powinny zapewniać wydajność i bezpieczeństwo
\end{itemize}

\subsection{Dysk}
\subsubsection{Budowa}
\begin{itemize}
\item głowica
\item talerz
\item ścieżka
\item cylinder
\item blok
\item sektor
\end{itemize}

\subsubsection{Czas odczytu}
time = seek time (head)(longest?) + rotation delay + transfer time

\subsubsection{Sposób dostępu}
\begin{itemize}
\item random (1o-krotni wolniejsze)
\item następny blok
\item sekwencyjny
\end{itemize}

\paragraph{Przykład}
\begin{verbatim}
transfer rate = 4000 KB
avg seek time = 0.01 s
page          = 2KB
\end{verbatim}

\subparagraph{Random}
1 strona
\begin{verbatim}
2 KB / (0.01 s + (2 KB / ( 4000 KB/s ))) = 190 KB/s
\end{verbatim}
\subparagraph{Sekwencyjny}
3o stron
\begin{verbatim}
60 KB / (0.01 s + (60 KB / ( 4000 KB/s ))) = 2400 KB/s
\end{verbatim}

\subsubsection{Wydajność}

\paragraph{Poprawa prędkości odczytu}
\begin{itemize}
\item odpowiednia organizacja przestrzeni dyskowej
\item szeregowanie operacji we/wy (sterowanie ruchem głowicy)
\item bufor dla zapisu (np. w pamięci RAM)
\item bufor na dysku (zapis sekwencyjny do bufora a potem porozdzielanie w odpowiednie miejsca)
\end{itemize}

\subparagraph{\ac{MTTF}}
Średni czas spodziewanej bezawaryjnej pracy dysku

Typowy MTTF -- kilka-kilkadziesiąt lat

Prawdopodobieństwo awarii jest stosunkowo niskie

\paragraph{Bez nadmiarowości}
\begin{itemize}
\item 1 dysk: $ 100.000h \sim 11 lat $
\item 100 dysków: $ 1.000h \sim 41dni $
\end{itemize}
\subparagraph{Mirroring}
\begin{itemize}
\item średni czas $ (100.000 ^ 2)h / 10 \sim 100.000 lat $
\item ale prawdopodobieństwo awarii rośnie mocno z wiekiem
\item rzeczywisty czas rzędu kilkudziesięciu lat
\end{itemize}
\subparagraph{Bit--level striping}
\begin{itemize}
\item np macierz 8 dysków, i-ty bit umieszczony na i-tym dysku
\item 8x szybszy dostęp
\end{itemize}
\subparagraph{Block--level striping}

\subsubsection{\ac{RAID}}
\paragraph{Co to i do czego służy?}
\begin{itemize}
\item poprawa wydajności - zrównoleglenie operacji we/wy
\item poprawa bezpieczeństwa - nadmiarowość
\end{itemize}

\paragraph{Typy \acs{RAID}}
\begin{enumerate}
\item \ac{RAID}0 -- wysoka wydajność, utrata danych nie może być problemem
\item \ac{RAID}1 -- wydajny ale kosztowny
\item \ac{RAID}3 -- szybki transfer danych
\item \ac{RAID}5 -- lepszy niż \ac{RAID}3 dla dostępu typu ``random``
\item \ac{RAID} $>$ 5 -- raczej niestetosowany
\end{enumerate}

Jeśli stać nas na \ac{RAID}0$+$1 to jest najlepsze rozwiązanie, jeśli nie to \ac{RAID}5

\subsubsection{Inne sposoby poprawy wydajności}
\begin{itemize}
\item mirroring na poziomie \ac{SZBD} i systemu
\item sterowanie położeniem danych na dysku (bliżej środka)
\item fragmentacja/grupowanie danych
\begin{itemize}
\item klastry
\item fragmentacja tabel
\item separowanie danych na poziomie fizycznym
\end{itemize}
\end{itemize}

\subsection{Sposoby przechowywania danych}
\begin{itemize}
\item plik, rekord, blok
\item tabela, wiersz, indeks, baza
\item relacja między poziomem logicznym a fizycznym
\begin{itemize}
\item plik składa się z bloków (a nie pojedynczych bitów [odczyt])
\item format rekordu: stały lub zmienny
\end{itemize}
\end{itemize}

\subsubsection{Stały format rekordu}
\paragraph{Zawartość}
\begin{itemize}
\item liczba pól
\item typ każdego pola
\item kolejność pól w rekordzie
\item definiuje rekord
\end{itemize}

\paragraph{Zalety}
\begin{itemize}
\item umożliwia łatwy dostęp
\item prostota implementacji
\end{itemize}


\paragraph{Wady}
\begin{itemize}
\item tylko jeden typ rekordy w danym pliku
\item dopisywanie na koniec
\item usuwanie rekordów
\begin{itemize}
\item flaga ``deleted``
\item lista usuniętych rekordów (dodawanie może ją wykrzoystywać)
\item jako że więcej INSERT niż DELETE to nie jest problem
\end{itemize}
\item jeśli rozmiar bloku nie jest wielokrotnością rozmiaru rekordu to niektóre
    rekordy będą wymagały dwóch odczytów
\end{itemize}

\subsubsection{Zmienny format rekordu}
\paragraph{Zawartość}
\begin{itemize}
\item każdy rekord zawiera opis formatu (self describing)
\end{itemize}
\paragraph{Zalety}
\begin{itemize}
\item rzadkie rekordy
\item formaty zmienne w czasie
\item rekordy różnych typów w jednym pliku
\item oszczędność miejsca
\begin{itemize}
\item sposoby przechowywania NULLi
\item wskaźniki
\item rezerwowanie miejsca dla rekordów (np rezerwowanie 255 dla VARCHAR \emph{zawsze})
\end{itemize}
\end{itemize}
\paragraph{Wady}
\begin{itemize}
\item marnuje ilość miejsca (więcej miejsca == więcej czasu do przetwarzania danych)
\item trudniejszy w implementacji
\end{itemize}

\paragraph{Slotted page}
\begin{itemize}
\item plik składa się ze stron które odpowiadają blokom na dysku (2kB (Oracle), 4kB, 8kB)
\item nagłówek (timestamps etc.)
\item tablica slotów (wskaźnik do początku wolnego miejsca, wskaźnik -- rozmiar, wskaźnik -- rozmiar ...)
\item elastyczny
\item powszechnie stosowany w \ac{SZBD}
\item w praktyce
\begin{itemize}
\item jedna strona == jedna tabela
\item sekwencyjne przetwarzanie danych z tabeli
\end{itemize}
\item wiele tabel w jednym pliku
\item jedna tabela w wielu plikach
\item reguła: jeżeli wiersz mieści się na stronie, to jest zawsze na jednej stronie
\begin{itemize}
\item więcej zajętego miejsca
\item efektywniejsze przetwarzanie danych
\end{itemize}
\end{itemize}

\subsubsection{Reprezentacja danych, nomenklatura}
\paragraph{Sposoby reprezentacji}
\begin{itemize}
\item każdej tabeli odpowiada plik -- mniejsze \ac{SZBD}
\item rezerwowany obszar dysku -- większe \ac{SZBD}
\end{itemize}

\paragraph{Przetrzeń dyskowa \ac{SZBD}}
\begin{itemize}
\item Oracle -- tablespace
\item Informix -- Dbspace
\item MSSQL, Sybase -- file group
\end{itemize}

\subparagraph{Informix}
\begin{itemize}
\item database, dbspace, chunk
\item przestrzeń dyskowa z jednego lub więcej chunków
\item chunk to jeden plik lub obszar dyskowy
\item przestrzeń dyskowa podzidzelona na jednostki logiczne (dbspace), każda
     składa się z jednego lub więcej plików
\item na serwerze może być wiele BD (w określonych Dbspaceach)
\end{itemize}

\subparagraph{MSSQL}
\begin{itemize}
\item database, filegroup, datafile
\item wiele baz danych
\item każdej bazy danych mamy przyzielaną przestrzeń dyskową
\item dla każdej bazy można stworzyć kilka grup plików (file group)
\end{itemize}

\subparagraph{ORACLE}
\begin{itemize}
\item tablespace, datafile
\item przestrzeń dyskowa podzielona na tablespace'y
\item tablespace to jeden lub więcej plików
\end{itemize}

\paragraph{Tabela}
\begin{itemize}
\item w momencie tworzenia serwer przydziela jej przestrzeń dyskową składającą
   się z obszaru stron na dysku nazywanego zakresem (extent)
\item extent: ciągly obszar stron na dysku
\item rozmiar zwykle kilka lub kilkanaście stron (można nim sterować)
\item dopisywanie wierszy do tabeli powoduje wypełnianie stron w ramach extentu
\item jeżeli brakuje miejsca to przydzielany jest kolejny extent
\end{itemize}

Rozmiar extentu może być zmieniony (od danego momentu extenty większe). Można
też automatycznie zwiększać rozmiar extentu (np. co 16 extent podwajamy)

Extenty nie są zwalniane automatycznie (wyjątek: tabele tymczasowe) -- dlatego
że zakładamy, że z reguły tabele się rozrastają a nie kurczą.

% Oracle (PCTFREE, PCTUSED)

\paragraph{Cluster}
Przechowywanie dwóch (lub wiecej) tabel łącznie na poziomie fizycznym (razem). Wydajne, gdy
najczęstszym sposobem ich przeglądania jest JOIN.

% * ORACLE:
%   CREATE TABLE dept (bla bla)
%   CLUSTER emp_dept(deptno);


\paragraph{Fragmentacja tabel}
Dystrybucja danych z jednej tabeli pomiędzy wiele dbspace'ów.
 % * INFORMIX:
     % * FRAGMENT BY ROUND ROBIN (bez konkretnego pomyslu)
       % IN dbspace1, dbspace2, dbspace3
     % * FRAGMENT BY EXPRESSION
       % employee_num <= 2500 IN dbspace1,
       % employee_num > 2500 IN dbspace2,

 % * ORACLE:
     % PARTITION BY RANGE (week_no)
     % (PARTITION sales1 VALUES LESS THAN (4) TABLESPACE ts1)

\paragraph{Podsumowanie}
\begin{itemize}
\item dążymy do tego żeby tabele były przechowywane w ciągłych obszarach na dysku
\begin{itemize}
\item w ogólnym przypadku -- trudne
\item pewnym rozwiązaniem jest pamiętanie danych w ciągłych extentach
\item warto czasem zreorganizowac strukturę extentów aby uzyskać ciągły obszar
\end{itemize}
\item czasami sens ma partycjonowanie/fragmentacja danych
\begin{itemize}
\item zrównoleglanie operacji we/wy
\item zysk w przypadku wielu małych transakcji
\item zysk w przypadku długich operacji
\end{itemize}
\item w pewnych przypadkach sens ma tworzenie struktur typu cluster
\begin{itemize}
\item gdy wiekszosc operacji dla tych tabel to JOIN
\item tabele nie są przeglądane samodzielnie (``podatek``)
\end{itemize}
\end{itemize}

\section{Indeksy}
Indeks może być plikiem płaskim, strukturą drzewiastą, hashem, który pozwala na
przyspieszenie dostępu do danych.

Można używać go na dwa sposoby:
\begin{itemize}
\item w celu uzyskania dostępu o charakterze bezpośrednim
\item w celu uzyskania dostępu sekwencyjnego (dostęp zgodny z porządkiem wyznaczonym przez indeks)
\end{itemize}

\subsection{Podział}
\begin{itemize}
\item indeksy płaskie -- uporządkowane zbiory indeksujące
\item indeksy bazujące na B-drzewach
\item indeksy - struktury typu hash
\item indeksowanie po kilku atrybutach
\end{itemize}

\subsection{Budowa}
\begin{itemize}
\item klucz (search key) -- atrybut/zbiór atrybutów, wg których wyszukujemy
\item zbior indeksujacy -- rekordy postaci search--key $=>$ pointer
\item indeks jest mniejszy od zbioru, który podlega indeksowaniu
\end{itemize}

\subsection{Podstawowe typy indeksów}
\begin{itemize}
\item uporządkowane -- klucze są uporządkowane
\item hash -- klucze są rozmieszczone równomiernie (zgodnie z funkcją haszujacą)
\end{itemize}

\subsection{Miary efektywności indeksów}

\begin{itemize}
\item dostęp do danych
\begin{itemize}
\item rekordy o określonej wartości atrybutu (rekordy które spełniają warunek)
\item rekordy które nie spełniają warunku dla określonego atrybutu
\end{itemize}
\item czas dostępu do danych
\item czas potrzebny na dopisanie rekordu
\item czas potrzebny na usunięcie rekordu
\item narzut wynikający z przestrzeni zajmowanej przez indeks
\end{itemize}

\subsection{Indeksy primary/secondary}

\subsubsection{Primary}
\begin{itemize}
\item uporządkowanie wg indeksu zgodne z fizycznym uporządkowaniem danych
\item czasami nazywane grupującymi (clustering index)
\item indeks gesty (dense index) -- rekord indeksu dla każdej wartości klucza
\item indeks rzadki (sparse index)
\item indeksy wielopoziomowe (płaski indeks do płaskiego indeksu)
\item duplikaty (reprezentowanie tylko raz wartości klucza w pliku -- optymalne rozwiązanie, wciąż indeks gęsty)
\end{itemize}
\subsubsection{Secondary}
\begin{itemize}
\item uporządkowanie nie jest zgodne z fizycznym uporządkowaniem
\item nazywane non--clustering index
\item indeksy rzadkie -- nie mają sensu
\item duplikaty (buckets)
\end{itemize}

\subsection{Uwagi}
\begin{itemize}
\item generalnie indeks przyspiesza dostęp do danych
\item dodatkowy koszt związany z modyfikacją danych
\item jeśli indeks jest duży to spada wydajność dostępu do danych (dla płaskich plikłw indeksujących)
\item dostęp sekwencyjny
\begin{itemize}
\item przy użyciu indeksu primary -- efektywny
\item przy użyciu indeksu secondary -- o wiele bardziej kosztowny
\end{itemize}
\item indeksy rzadkie są mniejsze ale trzeba dodatkowo realizować wyszukiwanie na poziomie danych
\item w przypadku indeksów gęstych niektóre operacje mogą być zrealizowane przy pomocy samego indeksu
\item w przypadku rzadkich w zasadzie też, ale jest zdecydowanie mniej możliwości
\end{itemize}

\subsection{\ac{B--Tree}}
Wygląd węzła: $ K_1, P_1, K_2, P_2, \ldots, K_n, P_n $
\begin{description}
\item[K] klucz
\item[P] pointer
\item[n] rozmiar
\end{description}
Klucze są uporządkowane.

\subsubsection{B+ drzewa}
Głębokość B+ drzewa: $ \log_{\frac{n}{2}}{K} $
\begin{description}
\item[K] liczba kluczy
\end{description}

\begin{itemize}
\item B-drzewa to najczęstszy sposób organizacji
\item wydajny jeśli chodzi o dostęp \emph{random}
\item wydajny jeśli chodzi o dostęp sekwencyjny
\end{itemize}

\subsection{Hash}
\begin{itemize}
\item funkcja haszujaca: $ key => h(key) $
\item statyczne lub dynamiczne (linear hashing, extensible hashing)
\item dają lepsze efekty jeśli chodzi o dostęp bezpośredni
\item problemy przy zapytaniach o zakres wartości
\end{itemize}

% SQL - indeksy
%
% CREATE INDEX <index-name> ON <relation-name> (<attribute-list>)
%
% CREATE INDEX b-index ON branch(branch-name)
%
% CREATE UNIQUE INDEX b-index ON branch(branch-name)
%
% DROP INDEX <index-name>
%
% FILL FACTOR <procent>
%
% FILL FACTOR 10%

\section{ACID}
\subsection{Atomicity, Consistency}
\subsubsection{Dlaczego?}

\begin{itemize}
\item możliwość awarii systemu podczas transakcji
\item równoczesny dostęp do danych
\item równoczesne wykonywanie transakcji
\end{itemize}

\subsubsection{Własności transakcji}
\paragraph{Consistency}
\begin{verbatim}
1. READ(A)
2. A = A - 50
3. WRITE(A)
4. READ(B)
5. B = B + 50
6. WRITE(B)
7. A + B = const
\end{verbatim}
Na przykład awaria między 3 i 4 powoduje, że baza powróci do stanu pierwotnego.

\paragraph{Trwałość}
Zmiany mają charakter trwały.

\paragraph{Izolacja}
Transakcje są wykonywane w całowitej izolacji (dla innych transakcji nie są widoczne
do czasu zatwierdzenia.

\begin{comment}

Stany transakcji:

 active -> partially commited -> commited
 active -> failed
 partially commited -> failed -> aborted

 Gdy nastąpi awaria, to tranakcja zostaje w stanie dowolnym (!)
 Po restarcie SZBD przegląda niedokończone transakcje i doprowadza je do końca
\end{comment}

\subsubsection{W jaki sposób zapewnić transakcyjność?}
\begin{itemize}
  \item shadow database: kopiujemy bazę, i po udanej transakcji usuwamy starą bazę i wskaźnik wskazuje na nową
  \begin{itemize}
    \item prosta implementacja
    \item nieefektywna (kopiowanie \emph{całej} bazy danych?!)
    \item krótkie transakcje czekają na jedną długą
  \end{itemize}
  \item algorytmy zapewniające niepodzielność i trwałość
  \item metody pozwalające odtworzyć stan bazy w przypadku awarii, powszechnie stosujemy system logów
\end{itemize}
\subsubsection{Awarie transakcji}
\begin{itemize}
\item użytkownik -- rollback (jawnie)
\item serwer -- na przykład naruszenie warunku integralnościowego
\item awarie aplikacji (awaria połączenia itp.)
\item awarie na poziomie serwera baz danych
\begin{itemize}
  \item system crash (utrata danych w pamięci)
  \item uszkodzenie dysku (utrata danych na dysku)
  \end{itemize}
\end{itemize}

\begin{description}
  \item[INPUT(X)] blok z dysku zawierający element X jest kopiowany do pamięci
  \item[READ(X, t)] jeżeli w pamięci nie ma bloku X, to INPUT(X), następnie t := x
  \item[WRITE(X, t)] jeżeli bloku zwierającego X nie ma w pamięci to INPUT(X), następnie X := t
  \item[OUTPUT(X)] zawartość bufora kopiowania na dysk
\end{description}

\begin{tabular}{r|c|c|c|c|c}
           & t  & MA & MB & DA & DB \\
\hline
READ(A, t) & 8  & 8  &    & 8  & 8 \\
t := t * 2 & 16 & 8  &    & 8  & 8 \\
WRITE(A, t)& 16 & 16 &    & 8  & 8 \\
READ(B, t) & 8  & 16 & 8  & 8  & 8 \\
t := t * 2 & 16 & 16 & 8  & 8  & 8 \\
WRITE(B, t)& 16 & 16 & 16 & 8  & 8 \\
OUTPUT(A)  & 16 & 16 & 16 & 16 & 8 \\
OUTPUT(B)  & 16 & 16 & 16 & 16 &16 \\
\end{tabular}

\subsubsection{Logi}
\paragraph{Struktura}
\begin{description}
  \item[$<$START T$>$] rozpoczęcie transakcji T
  \item[$<$T, X, v$>$] T -- transakcja, X -- el. danych, v -- wartość przed modyfikacją
  \item[$<$COMMIT T$>$] zakończenie transakcji
\end{description}

Log może służyć do operacji undo (wycofania transakcji)

\paragraph{Implementacja}
\begin{itemize}
  \item rekord logu dla każdej operacji
  \item rekord logu musi osiągnąć dysk zanim zmodyfikowany bufor zostanie zapisany
     na dysk (\ac{WAL})
  \item przed commitem wszystkie operacje muszą być zapisane na dysk
\end{itemize}

\paragraph{Podczas awarii}
\begin{itemize}
  \item wpisz $<$ABORT T$>$ do logu
  \item jeśli transakcja zapisuje informacje na dysk dopiero po zakończeniu
     wszystkich operacji to nie trzeba robić odtwarzania w przypadku błędu
     (wystarczy abort do logu)
  \item transakcje niekompletne: jeśli jest $<$START T$>$ a nie ma $<$COMMIT T$>$ ani $<$ABORT T$>$
  \item podczas procesu odtwarzania awaria nie jest problemem: po prostu powtarzamy proces
     odtwarzania
\end{itemize}

\paragraph{Checkpoint}
Operacja odtwarzania wymaga przeglądnięcia całego logu. Rozwiązaniem są \emph{checkpointy}.
\begin{itemize}
  \item zatrzymaj ``nowe transakcje``
  \item poczekaj aż bieżące transakcje się skończą (COMMIT lub ABORT)
  \item zapisz bufory na dysk
  \item zapisz informacje o CHECKPOINTcie do logu ($<$CHECKPOINT$>$)
\end{itemize}
Wtedy możemy zacząc odwarzanie od \emph{checkpointu}. Typowy system ma checkpoint co kilka minut.

\subparagraph{Minusy algorytmu CHECKPOINT}
\begin{itemize}
  \item żadnych nowych transakcji w tym czasie
  \item czekanie na koniec transakcji
\end{itemize}

  Rozwiązanie:
\paragraph{Nonquiscent checkpoint}
\begin{itemize}
  \item $<$START CHECKPOINT(AT1, AT2, \ldots)$>$ (ATN -- aktywana transakcja N)
  \item nie wstrzymujemy nowych transakcji
  \item po zakończeniu transakcji z listy $<$END CHECKPOINT$>$
\end{itemize}

Awaria w trakcie \emph{checkponitu}, trzeba:
\begin{itemize}
  \item odtworzyć transakcje, które rozpoczęły się po $<$START CHECKPOINT$>$
  \item wszystkie transakcje z listy przy $<$START CHECKPOINT$>$
\end{itemize}

Awaria po $<$END CHECKPOINT$>$
\begin{itemize}
  \item odtworzyć transakcje po $<$START CHECKPOINT$>$
\end{itemize}

  %UNDO:
   %* pewne transakcje które wyglądają jakby były zaitwerdzone mogą zostać wycofane
   %* COMMIT dopiero po zapisaniu wszystkich danych na dysk
   %* problem w przypadku odtwarzania backupu
%
  %REDO:
   %* wymaga modyfikowania ...

  Redo/undo logging.
  \begin{itemize}
    \item rekord logu zawiera starą i nową wartość: $<$T, X, v, w$>$
    \item rekord logu dla każdej operacji
    \item zapisz log na dysk zanim bufor X zostanie zapisany na dysk
    \item zapisz log po każdym $<$COMMIT T$>$
  \end{itemize}

  \begin{itemize}
    \item rolling back
    \begin{itemize}
      \item konstruuj listę zatwierdzonych transakcji -- S
      \item jeśli transakcja nie jest na liście S wykonaj UNDO
    \end{itemize}
    \item rolling forward
    \begin{itemize}
      \item wykonaj operację REDO dla transakcji z listy S
    \end{itemize}
  \end{itemize}

    %..........dbdump.................lastneededundo................checkpoint
    %not needed             not needed                    not needed
     %for media         for undo after                for redo after
      %recovery         system failure                system failure

\subsection{Isolation}
Najprostsze rozwiazanie: seryjne wykonywanie transakcji.
Trudniej: równolegle (ale szybciej)

\subsubsection{Właściwości transakcji}
\begin{itemize}
  \item zużycie I/O
  \item zużycie CPU
  \item różnorodność: dużo krótkich transakcji lub ``długie`` + ``krotkie`` -- potrzebne rozwiązanie
\end{itemize}

\subsubsection{Integralność danych}
\begin{itemize}
  \item transakcja zapewnia integralność
  \item seryjne transakcje -- nie ma problemu
  \item równoległe transakcje -- problem
\end{itemize}

\paragraph{Problemy wynikające z równoczesnego dostępu}
\begin{itemize}
  \item problem utraconej modyfikacji (lost update)
  \item zależność od niezatwierdzonej wartości (dirty read, uncommited dependency)
  \item niespójna analiza (inconsistent analysis, nonrepeatable read) -- transakcja dwukrotnie odczytuje
      tą samą jednostkę danych (wiersz tabeli) i dostaje różne dane (w międzyczasie była modyfikacja)
  \item phantom read -- odczyt danych, które pojawiły się podczas transakcji (INSERT)
\end{itemize}

Zapewnienie wszystkich reguł jest \emph{bardzo} kosztowne i zazwyczaj są pewne odstępstwa.

\subsubsection{Poziom izolacji}
Pewne ustawienie, które definiuje jakie zapewniamy rozwiązania izolacji (trzeba
wybrać między kosztem obsługi a zapewnioną izolacją).

\begin{comment}
\begin{itemize}
  \item transakcje to programy
  \item możliwe różne uszeregowanie operacji
  \item trudno analizować czy transakcje zależą od siebie czy nie
  \item ograniczamy tą analizę do READ i WRITE
\end{itemize}

Przykład:
  T1:
    1. READ(A)
    2. A = A + 100
    3. WRITE(A)
    4. READ(B)
    5. B = B + 100
    6. WRITE(B)

  T2:
    1. READ(A)
    2. A = A * 2
    3. WRITE(A)
    4. READ(B)
    5. B = B * 2
    6. WRITE(B)

  CONSTRAINT A == B

  * transakcje wykonywane w kolejności T1, T2 -- zapewniony constraint
  * kolejność T2, T1 -- zapewniony constraint ale \emph{inny wynik}
  * T1.1, T1.2, T1.3, T2.1, T2.2, T2.3, T1.4, T1.5, T1.6, T2.4, T2.5, T2.6 -- wynik okej
  * T1.{1-3}, T2.{1-6}, T1.{4-6} -- nie spełniona integralność
  * to co powyzej ale mnozenie razy 1 -- spełniona integralność

  Które są dobre? (niezależnie od danych wejściowych i operacji w transakcji)

Koniec przykładu.

Rozwiązywanie problemu izolacji:

1. Wyróżniamy transkacje READ i WRITE w transakcji (szeregowalność konfliktów)
\begin{itemize}
\item jeżeli instrukcje odnoszą się do różnych danych to można je zamienić miejscami
\item jeżeli odnoszą się do tych samych danych i przynajmniej jedna jest WRITEt to jest \emph{konflikt}
\end{itemize}

Uszeregowanie S:
 * I_i, I_j -- dwie kolejne instrukcje
 * jeśli nie są w konflikcie to można je zamienić
 * dostajemy uszregowanie S'
 * S i S' są równoważne
 * S' jest serializowalny, szeregowalny -- daje te same wyniki
Definicja: plany są równoważne ?
Definicja: plan szeregowalny: plan jest szregowalny ze wzgłedy na konflikt jesśli jest on zgodny z planem
seryjnym (sekwencyjnym)

Plan może być przekształcony do uszeregowania sekwencyjnego <T1, T2> przez serię zamian instrukcji, które
nie są w konflikcie.

Istnieją plany, których nie da się uzyskać tą metodą a dają taki sam wynik (ale znalezienie ich jest
kosztowne)

2. Odniesienie do READ/WRITE -- szeregowalność widoków)
 * view serializability
 * view equivalent
Reguły:
 * dla każdej danej Q jeśli Ti czyta początkową wartość w planie S to musi także czytać w S'
 * dla każdej danej Q jeśli Ti wykonuje READ(Q) w S i wartość Q jest ``wyprodukowana`` przez Tj
   to w  S' musi być tak samo
 * dla każdej danej Q jesśli Ti wykonuje końcowy zapis WRITE(Q) to S' także musi go wykonywać
   (zapewnia takie same wyniki planów)

 * szeregowanie konfliktów zawiera się w szeregowaniu widoków (ale nie na odwrót)

    T2    |   T4     |   T6
 ---------+----------+---------
  READ(Q) |          |
          | WRITE(Q) |
  WRITE(Q)|          |
          |          | WRITE(Q)


AWARIE TRANSAKCJI

 * jeżeli awarii uległa Ti to trzeba ją wycofać i wszystkie te które są od niej zależne
   (takie które przeczytały to co zapisała Ti)
 * musimy limitować uszeregowania do takich, które pozwalają na wycofanie transakcji zależnych

 T8      |     T9
 --------+--------
 READ(A) |
 WRITE(A)|
         | READ(A)
 READ(B) |

 * Jeśli COMMIT<T9> byl zaraz po READ(A) to taka sytuacja powoduje brak możliwości odtworzenia
   (nonrecoverable)
 * uszeregowania odtwarzalne (recoverable) -- jeśli transakcja Tj czyta zapisane Ti to COMMIT Tj
   musi nastąpić \emph{po} COMMIT Ti

3. Uszeregowania ``wolne`` od kaskadowego wycofywania (``cascadeless schedule``)
Jeżeli Tj czyta dane zapisane przez Ti to Ti musi się zakończyć zanim Tj przeczyta dane
Każde uszeregowanie ``cascadeless`` jest ``recoverable``

Kaskadowe wycofywanie transakcji
  * T10, T11, T12, jeśli T10 padnie to trzeba wycofać T11 i T12

Rozwiązania:
 * można analizować czy uszeregowanie spełnia kryteria:
   * ale ``conflict`` zlożoność takiej analizy $n^2$
   * view $2^n$

Protokoły zapewniające pożądane cechy uszregeowania:
 * wiele
 * m.in. ``lock based protocols`` -- blokady, najpopularniejsze

Poziomy izolacji:
 * serializable (default)
 * repetable read
 * read commited (most often)
 * read uncommited
 * SET ISOLATION LEVEL <typ>

Zerknąć na http://www.postgresql.org/docs/8.3/static/transaction-iso.html#MVCC-ISOLEVEL-TABLE

Szeregowalność według jakiego ``punktu``?
\begin{itemize}
\item dowolny
\item moment COMMIT (do tego dążymy)
\item moment rozpoczęcia
\end{itemize}

Metody pozwalające zarządzać równoczesnym dostępem (protokoły)
 * \ac{2PL}
  * strict \ac{2PL}
  * rigorous \ac{2PL}
 * tree
 * timestamp
 * validation
 * multiversion
  * timestamp
  * two-phase locking


%% WYKŁAD 15.12.2008

Schematy zarządzania równoczesnym dostępem
 * Multiversion Timestamp Ordering
 * Multiversion Two-Phase Locking

Muliversion schemes:
 * w przypadku modyfikacji Q system przez pewien czas przechowuje poprzednią wersję Q
 * każda modyfikacja tworzy nową wersję danych
 * wersje są rozpoznawane na podstawie znaczników czasowych
 * operacje czytania nie muszą czekać na dane

Warianty:
 1. znaczniki czasowe + wielowersyjność
 2. wielowersyjność + 2PL

1.a Dla każdego elementu pamiętamy znacznik czasu ostatniej operacji write oraz read
    (R-timestamp, W-timestamp)
1.b W-timestamp aktualizowany podczas zapisu
1.c R-timestamp aktualizowany podczas odczytu

2. Transakcje modyfikujące dane stosują się do reguł protokołu ``rigorous two-phase locking``
  (zamki trzymane są do zakończenia transakcji). Z każdym elementem skojarzony jest pojedyńczy
  znacznik.

% BUDOWA I ZASADA DZIALANIA OPTYMALIZATORA KOSZTOWEGO
Zapytanie:
1. Parsing and translation (zamiana na postać pośrednią -- wyrażenie w algebrze relacji)
2. Optimization (odwołuje się do danych statystycznych aby optymalizować)
3. Evaluation

Optymalizator analizuje plany i wybiera ten o najmniejszym koszcie.

Generowanie planu:
 * plan początkowy, zgodny z definicją zapytania, zwykle mało efektywny
   * dostajemy operacje algebry
   * do tego dobieramy operacje na poziomie fizycznym
 * generujemy kolejne plany przez przekształcenie wyrażeń algebry i dobór operacji
   na poziomie fizycznym. Wybeiramy go, jeżeli koszt jest niższy.

Szacowanie kosztów:
 * wykorzystanie CPU
 * wykorzystanie pamięci
 * komunikacja
 * operacje I/O -- najważniejszy

Na podstawie:
 * rozmiarów relacji
 * rozmiaru zbiorów pośrednich
 * rozmiaru zbiory wynikowego
 * indeksy, rodzaj
 * koszt operacji na podstawie danych statystycznych

Algebra relacji:
 * selekcja
 * projekcja
 * iloczyn kartezjański
 * część wspólna zbiorów
 * różnica zbiorów
 * suma zbiorów

Informacje statystyczne

 * dla poszczególnych relacji

 n_r  liczba krotek w relacji r
 b_r  liczba blokow
 s_r rozmiar krotki
 f_r liczba krotek w bloku

 V(A, r) liczba unikalnych wartosci dla atrybutu A
 SC(A,r) selection cardinality srednia ilosc rekordow spelniajacych warunek dla atrybutu A

Sortowanie

 * Kiedy jest potrzebne
  - ORDER BY, DISTINCT
  - niektore operacje (np. JOIN) moga byc realizowane efektywnie jesli dane sa posortowane

 * Sortowanie vs uporzadkowanie danych
  - uporzadkowanie moze byc zrealizowane przy pomocy indeksow (uporzadkowane "logicznie")
  - czasem mimo tego ze dostepne jest takie uporzadkowanie logiczne warto posortowac dane

 * W pamieci operacyjnej
  - nie zawsze mozliwe

 * Sortowanie na dysku
  - pamiec operacyjna + dysk
  - efektywnosc procesu sortowania zalezy od tego jak duzy obszar roboczy zostanie przydzielony w pamieci operacyjnej
  - algorytm externam sort-merge

Externam sort-merge
 * zakladamy, ze mamy M blokow w pamieci przeznaczonych na sortowanie
 * Sortowanie wykonujace jest w nastepujacych fazach
  - sort
   - tworzymy posortowane paczki (czy cos)

  - merge >:-|

  WORKING HARD OF HARDLY WORKING , EY ?

 * Miernikiem kosztu jest liczba dostepow do dysku
 * Koszt
  - liczba faz typu merge
  - koszt utworzenia "paczek"
  - koszt kazdego kroku merge
  - calkowity koszt

JOIN
 * Kilka algorytmow realizacji operacji JOIN
  - nested-loop join
  - block nested-loop join
  - indexed nested-loop join
  - merge-join
  - hash-join

 * Wybor algorytmu bazuje na analizie kosztowej

NESTED-LOOP JOIN
 * Zlaczenie r x_omega s

 * relacja r jest nazywana zewnetrzna relacja (outer relation)
 * relacja s jest nazywana wewnetrzna relacja (innej relation)
 * Algorytm nie wymaga zadnych indeksow i moze byc stosowany dla zlaczenia kazdego typu
 * bardzo kosztowny

NESTED-LOOP JOIN
 * w najgorszym przypadku (jeden blok w pamieci dla kazdej z relacji)
  n_r * b_s + b_r
 * w najlepszym przypadku (jesli relacja wewnetrzna miesci sie w pamieci)
  b_r + b_s
 * jesli mniejsza relacja miesci sie w pamieci , to powinna byc relacja wewnetrzna

BLOCK NESTED-LOOP JOIN
 * wariant algorytmu nested-loop join w ktorym kazdy blok relacji zewnetrznej przetwarzamy z relacja zewnetrzna

 * koszt
  - w najgorszym przypadku
  b_r * b_s + b_r
  - w najlepszym przypadku
  b_r + b_s

 * jesli zlaczenie jest rownozlaczeniem i dotyczy atrybutu ktory jest kluczem relacji wewnetrznej to przetwarzanie w petli wewnetrznej moze sie zatrzymac 
 * relacja wewnetrzna moze byc skanowana na przemian w przod i wstecz (zgodnosc z algorytmem LRU)

INDEXED NESTED-LOOP JOIN
 * zamiast skanowania relacji wewnetrznej mozna uzyc indeksu
  - zlaczenie jest rownorozlaczeniem
  - istnieje odpowiedni indeks dla relacji wewnetrznej
    - jezeli indeks nie istnieje to mozna rozwazyc utworzenie indeksu

 * jesli dostepne sa indeksy dla obu relacji to jako zewn. nalezy wybrac relacje o mniejszej liczbie krotek

Inne zagadnienia
- co z wynikami posrednimi
- zeby zrealizowac zadanie trzeba wykonac kilka operacji
- wyjscie operacji jest wejsciem dla kolejnej

Podsumowanie
- Optymalizacja kosztowa jest kosztowna
- Alternatywa
 - optymalizacja regulowa
 - rozwiazania mieszane
  - optymalizacja regulowa + kosztowa (odciecie bezsensownych rozwiazan)
  (optymalizacja regulowa nei sprawdzala sie sama bo nie brala pod uwage dystrybucji danych)
\end{comment}

\section{Dane przestrzenne}

\subsection{Zastosowania}
\begin{itemize}
\item architektura
\item planowanie przestrzenne
\item transport
\item systemy nawigacji
\item zarządzanie sytuacjami kryzysowymi
\end{itemize}

% \subsubsection{Terminologia}

\subsection{Model danych}
\begin{itemize}
\item przechowywane z reguły jako grafy
\item \emph{native} data type (np. \emph{SDO\_GEOMETRY} w Oracle)
\end{itemize}

\subsubsection{Model rastrowy}
Opiera się na zapisie macierzowym. Informacje reprezentowane są przez wartości
numeryczne umieszczone w komórkach macierzy. Liczby umieszczone w miacerzy mogą
reprezentować dowolne informacje (wysokość nad poziomem morza, wilgotność).

%TODO wady zalety

\subsubsection{Model geometryczny}
Wektory opisują pewne kształty (np. bryły), posiadamy pewien układ odniesienia
dla punktów.

Występuje pewna hierarchia obketów. Na szczycie \emph{warstwa przestrzenna},
której potomkami są na przykład: punkt, linia, ciąg linii, wielokąt.

Warstwa przestrzenna -- zbiór geometrii związany w jakiś sposób znaczeniowo, na
przykład sieć dróg, mapa miast, obszar leśny. Odpowiednikiem jest z reguły
kolumna w bazie danych.

\subsection{Indeksowanie}
Standardowe indeksy się \emph{nie sprawdzają}, dlatego potrzebne są dedykowane
rozwiązania.

Indeks przestrzenny -- umożliwia wykrzystywanie operatorów przestrzennych (niektóre
operatory nie mogą być wykonane bez indeksu).

\subsection{Przetwarzanie danych}
Najczęściej dane są dwuwymiarowe (można przechowywać 3, 4 wymiarowe). Można je przetwarzać
za pomocą bogatego zbioru opertorów.

\begin{description}
\item[SDO\_FILTER] w sposób przybliżony sprawdza czy dwa obiekty są w jakiejś zależności
\item[SDO\_NN] szwraca najbliższe obiekty danego obiektu
\item[SDO\_NN\_DISTANCE] odległość od obiektu zwróconego przez \emph{SDO\_NN}
\item[SDO\_RELATE] bada występowanie określonej relacji przestrzennej (ale dokładnie)
\item[SDO\_WITHIN\_DISTANCE] obiekty w pewnej odległości od danego obiektu
\end{description}

\subsubsection{Przykłady zapytań}
\begin{itemize}
\item W jakim państwie leży Praga?
\item Czy Praga leży w tym samym państwie co Pilzno?
\item Co leży bliżej Berlina: Gorzów Wielkopolski czy Szczecin?
\item Czy Polska graniczy z Republiką Czeską?
\item Jakie państwa sąsiadują z Polską?
\end{itemize}

\subsection{Implementacja w Oracle 10g/11g}
Podstawowy typ: \emph{SDO\_GEMOETRY} przechowywany w schemacie użytkowika
\emph{MDSYS}.  Jest to struktura zbudowana z prostych elementów takich jak
łuki, proste, punkty -- reprezentuje pewien kształt. Jest niepodzielna z punktu
widzenia operacji przestrzennych.

\subsubsection{SDO\_GTYPE}
Określa typ geometrii w formacie \emph{dltt}
\begin{description}
\item[d] liczba wymiarów
\item[l] dotyczy systemu \ac{LRS}
\item[tt] typ geometrii
\begin{description}
\item[00] unknown geometry
\item[01] point
\item[02] line or curve
\item[03] polygon
\item[04] collection
\item[05] multipoint
\item[06] multiline or multicurve
\item[07] multipolygon
\end{description}
\end{description}
\href{http://download.oracle.com/docs/cd/B10501\_01/appdev.920/a96630/sdo\_objrelschema.htm}{SDO\_GEOMETRY in Oracle}

\subsection{Standard SQL/MM Part 3: Spatial}

\newpage
\section{Akronimy}
\begin{acronym}
  \acro{2PL}{Two-Phase Locking}
  \acro{ACID}{Atomicity, Consistency, Isolation, Durability}
  \acro{B--Tree}{Balanced Tree}
  \acro{GIS}{Geographic Information System}
  \acro{ISAM}{Index Sequential Access Method}
  \acro{LRS}{Linear Referencing System}
  \acro{LRU}{Least Recently Used}
  \acro{MTTF}{Mean Time To Failure}
  \acro{RAID}{Redundant Array of Independent Disks}
  \acro{SQL}{Structured Query Language}
  \acro{SZBD}{System Zarządzania Bazą Danych}
  \acro{WAL}{Write-Ahead Logging}
\end{acronym}
\end{document}
