\documentclass[12pt]{article}

\usepackage{geometry}
\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage{polski}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{verbatim}
\usepackage{acronym}

\hypersetup{
  linkbordercolor={1 1 1},
  urlbordercolor={1 1 1}
}
\pagestyle{headings}

\author{Michał Bugno \and Antek Piechnik}
\title{Wykłady z OSZBD}

\begin{document}
\maketitle
\tableofcontents
\newpage

\section{Wstęp}
\subsection{Literatura}
\begin{itemize}
\item Silberschatz ``Database System Concepts``
\item Garcia-Molina, Ullman, Widom ``Database systems The Complete Book``
\item (!)Garcia-Molina, Ullman, Widom ``Implementacja Systemow Baz Danych``
\item Ramakrishan, Gecherke ``Database Managment Systems``
\item Date ``Wprowadzenie Do Baz Danych`` (uzupełniająca, raczej nie)
\item Celko ``SQL zaawansowane techniki programowania``
\end{itemize}

\subsection{Omawiane bazy danych}
\subsubsection{Komercyjne}
\begin{itemize}
\item Oracle
\item IBM INFORMIX
\item IBM DB2
\item MS SQL
\item Sybase
\end{itemize}

\subsubsection{Darmowe}
\begin{itemize}
\item PostgreSQL
\item MySQL
\end{itemize}

\subsection{Linki}
\begin{itemize}
\item \url{http://www.sqlservercentral.com}
\item \url{http://www.databaseweekly.com}
\item \url{http://www.oracle.com/oramag/index.html}
\item \url{http://www.db2mag.com}
\item \url{http://www.iiug.org}
\end{itemize}

\subsection{Plan}
\subsubsection{Semestr zimowy}
\begin{enumerate}
\item \ac{SZBD}
\begin{itemize}
\item pamięć, procesy, dysk
\item moduły funkcjonalne \ac{SZBD}, architektura klient/serwer
\end{itemize}
\item Fizyczna struktura danych
\begin{itemize}
\item struktura fizyczna zbiorów
\item metody przechowywania danych, organizacja dysków, \acs{RAID}
\item fragmentacja/partycjonowanie
\end{itemize}
\item Metody dostępu do danych, indeksowanie
\begin{itemize}
\item dostęp sekwencyjny
\item indeksy, B-drzewa, hash, bitmap, siatkowe (struktury wielowymiarowe)
\end{itemize}
\item Przetwarzanie transakcyjne
\begin{itemize}
\item pojęcie transakcji
\item \ac{ACID}
\end{itemize}
\item Metody realizacji przetwarzania transakcyjnego
\begin{itemize}
\item ACD
\end{itemize}
\item Równoczesny dostęp do danych
\begin{itemize}
\item poziomy izolacji
\item metody zarządzania równoczesnym dostępem
\item blokady, wielowersyjność
\end{itemize}
\item Realizacja operacji, optymalizacja
\begin{itemize}
\item algebra relacji
\item SQL, PL/SQL i podobne
\item sposoby realizacji operacji (SELECT, JOIN itp.)
\end{itemize}
\item Replikacja danych
\begin{itemize}
\item metody replikacji danych
\item synchronizacja danych
\end{itemize}
\item Bezpieczeństwo
\begin{itemize}
\item integralność, transakcje
\item archiwizacja, odtwarzanie
\item fault tolerance (\acs{RAID}, klastry, replikacja)
\end{itemize}
\item Administracja i optymalizacja wydajności serwera
\begin{itemize}
\item konfiguracja (specyficzne cechy SZBD)
\item strojenie
\end{itemize}
\item Przetwarzanie informacji przestrzennych, GIS
\begin{itemize}
\item metody, algorytmy, struktury danych
\item Oracle spatial, DB2, INFORMIX, MS SQL 2008
\end{itemize}
\item Przykłady SZBD
\begin{itemize}
\item IBM/Informix
\item IBM/DB2
\item Oracle
\item MSSQL Server
\end{itemize}
\end{enumerate}

\subsubsection{Semestr letni}
\begin{enumerate}
\item Hurtownie danych
\item Analiza danych
\item Exploracja danych
\end{enumerate}

\subsection{Laboratoria}
\begin{itemize}
\item podział na grupy na 2 semestry
\item Prowadzący
\begin{itemize}
\item Anna Zygmunt (pon. 11.oo - 12.3o, pt. 15.3o - 17.oo)
\item Robert Marcjan (pon. 9.3o - 11.oo)
\item Leszek Siwik (pt. 15.3o - 17.oo)
\end{itemize}
\end{itemize}

\section{\ac{SZBD}}
%* modele danych
%* szbd
%* architektury systemow baz danych
%* budowa wewnetrzna

\begin{description}
\item[Model danych] zestaw pojęć używanych do opisu danych
\end{description}

Modele danych:
\begin{itemize}
\item związków encji
\item sieciowy
\item hierarchiczny
\item relacyjny (mocna teoria (algebra relacji), udany, prosty)
\item obiektowy (nie tak wydajny jak relacyjny)
\item obiektowo-relacyjny
\end{itemize}

\subsection{Relacyjny model danych}
\subsubsection{Cechy}

\begin{itemize}
\item relacje, krotki, atrybuty
\item tabele, wiersze, kolumny
\item algebra relacji (prosta, przejrzysta)
\begin{itemize}
\item wejście: relacja1, relacja2 ..., wyjście: nowa relacja
\item operacje: selekcja, projekcja, złączenie (join), suma, różnica, przecięcie etc.
\end{itemize}
\item język \acs{SQL}
\end{itemize}

\subsubsection{Niezależność}
\begin{itemize}
\item możliwość modyfikacji definicji (schematu) na danym poziomie bez konieczności zmian na wyższym poziomie
   (poziom fizyczny, logiczny, prezentacji)
\item aplikacje są niezależne od tego jak dane są strukturalizowane i przechowywane
\end{itemize}

\subsubsection{Architektury}
\begin{itemize}
\item  mainframe
\item  file sharing, \acs{ISAM} (na plikach)
\item  client-server (klient nie ``dotyka`` serwera)
\item  architektury wielowarstwowe (3 warstwowe)
\item  architektury rozproszone
\begin{itemize}
\item  rozproszenie danych
\item powielanie (replikacja) danych
\item transakcje rozproszone
\end{itemize}
\item  architektury równoległe (w tym widzi się skok wydajności, dotychczasowe rozwiązania są już
   bardzo dobrze zoptymalizowane)
\end{itemize}

\subsubsection{Client--server}
\begin{itemize}
\item operacje ``klienta``
\item operacje ``serwera``
\item \ac{SQL}
\item stored procedures -- każdy ma własny język, nie ma zgodności (zmienne, pętle, nie ma struktur danych)
\item \ac{SQL} + możliwość wykonania programu na serwerze (SUM(kolumna) vs SELECT * a potem sumuj, programy w Java, C)
\end{itemize}

\subsubsection{Dlaczego \acs{SZBD}?}
\begin{itemize}
\item redundancja danych
\item spójność danych (dlaczego nie tylko w aplikacji? bo z reguły \ac{SZBD} żyje DŁUŻEJ niż aplikacja)
\item równoczesny dostęp do danych (nie trzeba przejmować się równoczesny dostępem)
\item transakcje (\ac{ACID})
\item bezpieczeństwo danych
\begin{itemize}
\item ochrona przed niepowołanym dostępem (bardzo dokładna kontrola np. konkretne kolumny)
\item odporność na awarię
\end{itemize}
\end{itemize}
Przetwarzanie powinno być \emph{efektywne}.

\subsection{Pamięć, dyski}
W \ac{SZBD} dane przechowywane są na dyskach. Ma to znaczenie przy ich projektowaniu.

\subsubsection{Hierarchia szybkości}
\begin{enumerate}
\item cache (najszybszy)
\item main memory
\item flash memory
\item magnetic disk
\item optical disk
\item magnetic tapes (najwolniejszy)
\end{enumerate}

\subsubsection{Podstawowe operacje}
\begin{description}
\item[READ] transfer z dysku do RAM
\item[WRITE] zapis z RAM na dysk
\end{description}
Te operacje są kosztowne w porównaniu do operacji w pamięci

\subsubsection{Komponenty tworzące \ac{SZBD}}
\begin{itemize}
\item dysk
\begin{itemize}
\item struktury przechowujące dane
\item struktury przechowujące opis danych
\item struktury zapewniające przetwarzanie transakcyjne
\item struktury zapewniające bezpieczeństwo
\end{itemize}
\item procesy
\begin{itemize}
\item operacje związane z funkcjonowaniem serwera
\item operacje wykonywane ``na zlecenie`` aplikacji klienckich
\end{itemize}
\item pamięć
\begin{itemize}
\item pula buforów
\item struktury kontrolne
\end{itemize}
\end{itemize}

Typowy system ma dużo więcej danych na dysku niż może przechowywać w pamięci.

\subsubsection{Sposoby zabezpieczeń}
\paragraph{\acs{RAID}}
\begin{itemize}
\item backup danych, backup logów (raz na jakiś czas zapisujemy dane, ciągle backupujemy logi)
\item w przypadku awarii restore danych a potem wykonujemy logi od ostatniego dobrego backupu
\end{itemize}

\paragraph{Replikacja}
\begin{itemize}
\item zabezpieczenie przed utratą wszystkiego (serwer wykonuje log i przesyła go gdzieś indziej, do innego serwera)
\item przybliżenie użytkownikowi danych (coraz mniejsza rola tej funkcji, przepustowość sieci rośnie)
\end{itemize}

\paragraph{Struktury dyskowe}
\begin{itemize}
\item czas dostępu do dysku jest bardzo wolny
\item operujemy na dużych zbiorach danych
\item powinny zapewniać wydajność i bezpieczeństwo
\end{itemize}

\subsection{Dysk}
\subsubsection{Budowa}
\begin{itemize}
\item głowica
\item talerz
\item ścieżka
\item cylinder
\item blok
\item sektor
\end{itemize}

\subsubsection{Czas odczytu}
time = seek time (head)(longest?) + rotation delay + transfer time

\subsubsection{Sposób dostępu}
\begin{itemize}
\item random (1o-krotni wolniejsze)
\item następny blok
\item sekwencyjny
\end{itemize}

\paragraph{Przykład}
\begin{verbatim}
transfer rate = 4000 KB
avg seek time = 0.01 s
page          = 2KB
\end{verbatim}

\subparagraph{Random}
1 strona
\begin{verbatim}
2 KB / (0.01 s + (2 KB / ( 4000 KB/s ))) = 190 KB/s
\end{verbatim}
\subparagraph{Sekwencyjny}
3o stron
\begin{verbatim}
60 KB / (0.01 s + (60 KB / ( 4000 KB/s ))) = 2400 KB/s
\end{verbatim}

\subsection{Wydajność}

\subsubsection{Poprawa prędkości odczytu}
\begin{itemize}
\item odpowiednia organizacja przestrzeni dyskowej
\item szeregowanie operacji we/wy (sterowanie ruchem głowicy)
\item bufor dla zapisu (np. w pamięci RAM)
\item bufor na dysku (zapis sekwencyjny do bufora a potem porozdzielanie w odpowiednie miejsca)
\end{itemize}

\paragraph{\ac{MTTF}}
Średni czas spodziewanej bezawaryjnej pracy dysku

Typowy MTTF -- kilka-kilkadziesiąt lat

Prawdopodobieństwo awarii jest stosunkowo niskie

\subsubsection{Bez nadmiarowości}
\begin{itemize}
\item 1 dysk: $ 100.000h \sim 11 lat $
\item 100 dysków: $ 1.000h \sim 41dni $
\end{itemize}
\paragraph{Mirroring}
\begin{itemize}
\item średni czas $ (100.000 ^ 2)h / 10 \sim 100.000 lat $
\item ale prawdopodobieństwo awarii rośnie mocno z wiekiem
\item rzeczywisty czas rzędu kilkudziesięciu lat
\end{itemize}
\paragraph{Bit--level striping}
\begin{itemize}
\item np macierz 8 dysków, i-ty bit umieszczony na i-tym dysku
\item 8x szybszy dostęp
\end{itemize}
\paragraph{Block--level striping}

\subsubsection{\ac{RAID}}
\paragraph{Co to i do czego służy?}
\begin{itemize}
\item poprawa wydajności - zrównoleglenie operacji we/wy
\item poprawa bezpieczeństwa - nadmiarowość
\end{itemize}

\paragraph{Typy \acs{RAID}}
\begin{enumerate}
\item \ac{RAID}0 -- wysoka wydajność, utrata danych nie może być problemem
\item \ac{RAID}1 -- wydajny ale kosztowny
\item \ac{RAID}3 -- szybki transfer danych
\item \ac{RAID}5 -- lepszy niż \ac{RAID}3 dla dostępu typu ``random``
\item \ac{RAID} $>$ 5 -- raczej niestetosowany
\end{enumerate}

Jeśli stać nas na \ac{RAID}0$+$1 to jest najlepsze rozwiązanie, jeśli nie to \ac{RAID}5

\paragraph{Inne sposoby poprawy wydajności}
\begin{itemize}
\item mirroring na poziomie \ac{SZBD} i systemu
\item sterowanie położeniem danych na dysku (bliżej środka)
\item fragmentacja/grupowanie danych
\begin{itemize}
\item klastry
\item fragmentacja tabel
\item separowanie danych na poziomie fizycznym
\end{itemize}
\end{itemize}

\subsection{Sposoby przechowywania danych}
\begin{itemize}
\item plik, rekord, blok
\item tabela, wiersz, indeks, baza
\item relacja między poziomem logicznym a fizycznym
\begin{itemize}
\item plik składa się z bloków (a nie pojedynczych bitów [odczyt])
\item format rekordu: stały lub zmienny
\end{itemize}
\end{itemize}

\subsubsection{Stały format rekordu}
\paragraph{Zawartość}
\begin{itemize}
\item liczba pól
\item typ każdego pola
\item kolejność pól w rekordzie
\item definiuje rekord
\end{itemize}

\paragraph{Zalety}
\begin{itemize}
\item umożliwia łatwy dostęp
\item prostota implementacji
\end{itemize}


\paragraph{Wady}
\begin{itemize}
\item tylko jeden typ rekordy w danym pliku
\item dopisywanie na koniec
\item usuwanie rekordów
\begin{itemize}
\item flaga ``deleted``
\item lista usuniętych rekordów (dodawanie może ją wykrzoystywać)
\item jako że więcej INSERT niż DELETE to nie jest problem
\end{itemize}
\item jeśli rozmiar bloku nie jest wielokrotnością rozmiaru rekordu to niektóre
    rekordy będą wymagały dwóch odczytów
\end{itemize}

\subsubsection{Zmienny format rekordu}
\paragraph{Zawartość}
\begin{itemize}
\item każdy rekord zawiera opis formatu (self describing)
\end{itemize}
\paragraph{Zalety}
\begin{itemize}
\item rzadkie rekordy
\item formaty zmienne w czasie
\item rekordy różnych typów w jednym pliku
\item oszczędność miejsca
\begin{itemize}
\item sposoby przechowywania NULLi
\item wskaźniki
\item rezerwowanie miejsca dla rekordów (np rezerwowanie 255 dla VARCHAR \emph{zawsze})
\end{itemize}
\end{itemize}
\paragraph{Wady}
\begin{itemize}
\item marnuje ilość miejsca (więcej miejsca == więcej czasu do przetwarzania danych)
\item trudniejszy w implementacji
\end{itemize}

\paragraph{Slotted page}
\begin{itemize}
\item plik składa się ze stron które odpowiadają blokom na dysku (2kB (Oracle), 4kB, 8kB)
\item nagłówek (timestamps etc.)
\item tablica slotów (wskaźnik do początku wolnego miejsca, wskaźnik -- rozmiar, wskaźnik -- rozmiar ...)
\item elastyczny
\item powszechnie stosowany w \ac{SZBD}
\item w praktyce
\begin{itemize}
\item jedna strona == jedna tabela
\item sekwencyjne przetwarzanie danych z tabeli
\end{itemize}
\item wiele tabel w jednym pliku
\item jedna tabela w wielu plikach
\item reguła: jeżeli wiersz mieści się na stronie, to jest zawsze na jednej stronie
\begin{itemize}
\item więcej zajętego miejsca
\item efektywniejsze przetwarzanie danych
\end{itemize}
\end{itemize}

\subsubsection{Reprezentacja danych, nomenklatura}
\paragraph{Sposoby reprezentacji}
\begin{itemize}
\item każdej tabeli odpowiada plik -- mniejsze \ac{SZBD}
\item rezerwowany obszar dysku -- większe \ac{SZBD}
\end{itemize}

\paragraph{Przetrzeń dyskowa \ac{SZBD}}
\begin{itemize}
\item Oracle -- tablespace
\item Informix -- Dbspace
\item MSSQL, Sybase -- file group
\end{itemize}

\subparagraph{Informix}
\begin{itemize}
\item database, dbspace, chunk
\item przestrzeń dyskowa z jednego lub więcej chunków
\item chunk to jeden plik lub obszar dyskowy
\item przestrzeń dyskowa podzidzelona na jednostki logiczne (dbspace), każda
     składa się z jednego lub więcej plików
\item na serwerze może być wiele BD (w określonych Dbspaceach)
\end{itemize}

\subparagraph{MSSQL}
\begin{itemize}
\item database, filegroup, datafile
\item wiele baz danych
\item każdej bazy danych mamy przyzielaną przestrzeń dyskową
\item dla każdej bazy można stworzyć kilka grup plików (file group)
\end{itemize}

\subparagraph{ORACLE}
\begin{itemize}
\item tablespace, datafile
\item przestrzeń dyskowa podzielona na tablespace'y
\item tablespace to jeden lub więcej plików
\end{itemize}

\paragraph{Tabela}
\begin{itemize}
\item w momencie tworzenia serwer przydziela jej przestrzeń dyskową składającą
   się z obszaru stron na dysku nazywanego zakresem (extent)
\item extent: ciągly obszar stron na dysku
\item rozmiar zwykle kilka lub kilkanaście stron (można nim sterować)
\item dopisywanie wierszy do tabeli powoduje wypełnianie stron w ramach extentu
\item jeżeli brakuje miejsca to przydzielany jest kolejny extent
\end{itemize}

Rozmiar extentu może być zmieniony (od danego momentu extenty większe). Można
też automatycznie zwiększać rozmiar extentu (np. co 16 extent podwajamy)

Extenty nie są zwalniane automatycznie (wyjątek: tabele tymczasowe) -- dlatego
że zakładamy, że z reguły tabele się rozrastają a nie kurczą.

% Oracle (PCTFREE, PCTUSED)

\begin{comment}

Cluster
	* Przechowywanie dwoch (lub wiecej) tabel lacznie na poziomie fizycznym (razem)
		- jesli najczestszym sposobem ich przegladania jest join
		- mozna stworzyc strukture typu cluster
	* ORACLE:
		CREATE TABLE dept (bla bla)
		CLUSTER emp_dept(deptno);
	
Fragmentacja tabel
	* dystrybujcja dany z jednej tabeli pomiedzy wiele dbspace'ow)
 	* INFORMIX:
	FRAGMENT BY ROUND ROBIN (bez konkretnego pomyslu)
		IN dbspace1, dbspace2, dbspace3
	FRAGMENT BY EXPRESSION
		employee_num <= 2500 IN dbspace1,
		employee_num > 2500 IN dbspace2,
		etc.	
	
	* ORACLE:
	PARTITION BY RANGE (week_no)
		(PARTITION sales1 VALUES LESS THAN (4) TABLESPACE ts1)

Podsumowanie
	* Dazymy do tego zeby tabele byly przechowywane w ciaglych obszarach na dysku
		- w ogolnym przypadku - trudne
		- pewnym rozwiazaniem jest pamietanie danych w ciaglych extentach
		- warto czasem zreorganizowac strukture extentow aby uzyskac ciagly obszar
		
	* Czasami sens ma partycjonowanie/fragmentacja danych
		- zrownoleglanie operacji we/wy
		- zysk w przypadku wielu malych transakcji
		- zysk w przypadku dlugich operacji
		
	* W pewnych przypadkach sens ma tworzenie struktur typu cluster
		- gdy wiekszosc operacji dla tych tabel operacje pobierania danych to JOIN
		- tabele nie sa przegladane samodzielnie ('podatek')
	
Indeksy
	* Indeksy plaskie
		- uporzadkowane zbiory indeksujace
	* Indeksy bazujace na B-drzewach
	* Indeksy - struktury typu hash
	* Indeksowanie po kilku atrybutach
	* Pojecie ogolne
		- Moze to byc plik plaski, struktura drzewiasta, hash
	* Moze byc uzywany na dwa sposoby
		- W celu uzyskania dostepu o charakterze bezposrednim
		- W celu uzyskania dostepu sekwencyjnego (dostep zgodny z porzadkiem wyznaczonym przez przez indeks)
	* Indeksowanie jest uzywane zeby przyspieszyc dostep
	* Klucz (search key) - atrybut/zbior atrybiutow wg ktorego wyszukujemy
	* Zbior indeksujacy - rekordy postacji search-key<-->pointer
	* Indeks jest mniejszy od zbioru ktory podlega indeksowaniu
	* Dwa podstawowe typy indeksow
		* uporzadkowane - klucze sa uporzadkowane
		* hash - klucze sa rozmieszczone rownomiernie (zgodnie z funkcja haszujaca)
		
Miary efektywnosci indeksow
	* Dostep do danych
		- rekordy o okreslonej wartosci atrybutu (rekordy ktory spelniaja warunek)
		- rekordy ktore nie spelniaja warunku dla okreslonego atrybutu
	* Czas dostepu do danych
	* Czas potrzebny na dopisanie rekordu
	* Czas potrzebny na usuniecie rekordu
	* Narzut wynikajacy z przestrzeni zajmowanej przez indeks
	
Indeksy primary/secondary
	* Primary
		- uporzadzkowanie wg indeksu zgodne z fizycznym uporzadkowaniem danych
		- czasami nazywane grupujacymi (clustering index)
	* Secondary
		- uporzadkowanie nie jest zgodne fizycznym uporzadkowaniem
		- nazywane non clustering index

Indeksy Primary
	* Indeks gesty (dense index) - rekord indeksu dla kazdej wartosci klucza
	* Indeks rzadki (sparse index)
	* Indeksy wielopoziomowe (plaski indeks do plaskiego indeksu)
	* Duplikaty (reprezentowanie tylko raz wartosci klucza w pliku - optymalnego rozwiazanie, wciaz indeks gesty)
	
Indeksy Secondary
	* Indeksy rzadkie - nie maja sensu
	* Duplikaty (buckets)

Indeksy - Uwagi
	* Generalnie indeks przyspiesza dostep do danych
	* Dodatkowy koszt zwiazany z modyfikacja danych
	* Jesli indeks jest duzy to spada wydajnosc dostepu do danych (dla plaskich plikow indeksujacych)
	* Dostep sekwencyjny 
		- dostep sekwencyjny przy uzyciu indeksu primary - efektywny
		- dostep sekwencyjny przy uzyciu indeksu secondary - o wiele bardziej kosztowny
	* Indeksy rzadkie sa mniejsze
		- ale trzeba dodatkowo realizowac wyszukiwanie na poziomie danych
	* W przypakdu indeksow gestych niektore operacje moga byc zrealizowane przy pomocy samego indeksu
		- w przypadku rzadkich w zasadzie tez, ale jest zdecydowanie mniej mozliwosci
		
Indeksy wielopoziomowe - B-drzewa
	* B- balanced - zrownowazone
	* Wezel
		K_1, P_1, K_2, P_2, ...., K_n, P_n
		- K - klucz
		- P - pointer
		- n - rozmiar
		- klucze sa uporzadkowane
		

B+ drzewa (wypelnienie wezlow)
  * Glebokosc B+ drzewa
    - K- liczba kluczy
    - Log_[n/2](K)
    - np. K = 1 000 000
          n = 100
          glebokosc = 4

  * B drzewa - najczestszy sposob organizacji
    - wydajny jesli chodzi o dostep "random"
    - wydany jesli chodzi o dostep sekwencyjny

Hash
  * Funkcja haszujaca
    - Key - > h(key)
  * Struktury typu hash
    - Statyczne
    - Dynamiczne (linear hashing, extensible hashing)
  * Podsumowanie
    - Struktury typu hash daja lepsze efekty jesli chodzi o dostep bezposredni
    - Problemy przy zapytaniach typu : zakres wartosci

SQL - indeksy

  CREATE INDEX <index-name> ON <relation-name> (<attribute-list>)

  CREATE INDEX b-index ON branch(branch-name)

  CREATE UNIQUE INDEX b-index ON branch(branch-name)

  DROP INDEX <index-name>

  FILL FACTOR <procent>

  FILL FACTOR 10%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% WYKLAD 17/11/2008
% ATOMICITY, CONSISTENCY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Zagadnienia do rozważenia:
 * możliwość awarii systemu podczas transakcji
 * równoczesny dostęp do danych, równoczesne wykonywanie transakcji

Własności transakcji
 * consistency
    read(A)
    A = A - 50
    write(A)
    read(B)
    B = B + 50
    write(B)
    A + B = const
    na przykład awaria między 3 i 4 powoduje, że baza powróci do stanu pierwotnego
 * trwałość
    zmiany mają charakter trwały
 * izolacja
    transakcje są wykonywane w całowitej izolacji (dla innych transakcji nie są widoczne
    do czasu zatwierdzenia

Stany transakcji:

 active -> partially commited -> commited
 active -> failed
 partially commited -> failed -> aborted

 Gdy nastąpi awaria, to tranakcja zostaje w stanie dowolnym (!)
 Po restarcie SZBD przegląda niedokończone transakcje i doprowadza je do końca

W jaki sposób zapewnić transakcyjność?

 * shadow database: kopiujemy bazę, i po udanej transakcji usuwamy starą bazę i wskaźnik wskazuje na nową
   (izolacja: po kolei)
   - prosta implementacja
   - nieefektywna (kopiowanie _całej_ bazy danych?!)
   - krótkie transakcje czekają na jedną długą

 * algorytmy zapewniające niepodzielność i trwałość
   Metody pozwalające odtworzyć stan bazy w przypadku awarii, powszechnie stosujemy system logów.
   - awarie transakcji:
    * użytkownik - rollback (jawnie)
    * serwer - na przykład naruszenie warunku integralnościowego
   - awarie aplikacji
    * awaria połączenia itp
   - awarie na poziomie serwera baz danych
    * system crash (utrata danych w pamięci)
    * uszkodzenie dysku (utrata danych na dysku)

   1. Akcje podejmowanie podczas normalnego wykonywania się transkcji
   2. Akcje podejmowane po awarii w celu odtworzenia stanu bazy

   INPUT(X) -- blok z dysku zawierający element X jest kopiowany do pamięci
   READ(X, t) -- jeżeli w pamięci nie ma bloku X, to INPUT(X), następnie t := x
   WRITE(X, t) -- jeżeli bloku zwierającego X nie ma w pamięci to INPUT(X), następnie X := t
   OUTPUT(X) -- zawartość bufora kopiowania na dysk

              | t  | MA | MB | DA | DB | LOG
   READ(A, t) | 8  | 8  |    | 8  | 8  | <START...>
   t := t * 2 | 16 | 8  |    | 8  | 8  |
   WRITE(A, t)| 16 | 16 |    | 8  | 8  |
   READ(B, t) | 8  | 16 | 8  | 8  | 8  |
   t := t * 2 | 16 | 16 | 8  | 8  | 8  |
   WRITE(B, t)| 16 | 16 | 16 | 8  | 8  |
   OUTPUT(A)  | 16 | 16 | 16 | 16 | 8  |
   OUTPUT(B)  | 16 | 16 | 16 | 16 |16  |

  LOG:
  <START T> -- rozpoczęcie transakcji T
  <T, X, v> -- T -- transakcja, X -- el. danych, v -- wartość przed modyfikacją
  <COMMIT T> -- zakończenie transakcji
  Log może służīć do operacji undo (wycofania transakcji)

  Rozwiązanie logów:
   * rekord logu dla każdej operacji
   * rekord logu musi osiągnąć dysk zanim zmodyfikowany bufor zostanie zapisany
     na dysk (WAL -- write ahead logging)
   * przed commitem wszystkie operacje muszą być zapisane na dysk

  W czasie awarii:
   * <ABORT T> do logu
   * jeśli transakcja zapisuje informacje na dysk dopiero po zakończeniu
     wszystkich operacji to nie trzeba robić odtwarzania w przypadku błędu
     (wystarczy abort do logu)
   * transakcje niekompletne: jeśli jest <START T> a nie ma <COMMIT T> ani <ABORT T>
   * podczas procesu odtwarzania awaria nie jest problemem: po prostu powtarzamy proces
     odtwarzania

  Operacja odtwarzania wymaga przeglądnięcia całego logu
  Rozwiązanie: co jakiś czas CHECKPOINT, czyli:
    * zatrzymaj ``nowe transakcje``
    * poczekaj aż bieżące transakcje się skończą (COMMIT lub ABORT)
    * zapisz bufory na dysk
    * zapisz informacje o CHECKPOINTcie do logu (<CHECKPOINT>)
  Wtedy możemy zacząc odwarzanie od CHECKPOINTu. Typowy system ma CHECKPOINT co kilka minut.

  Minusy algorytmu CHECKPOINT:
    * żadnych nowych transakcji w tym czasie
    * czekanie na koniec transakcji

  Rozwiązanie:
  NONQUISCENT CHECKPOINT
   * <START CHECKPOINT(AT1, AT2...)> (ATN - aktywana transakcja N)
   * nie wstrzymujemy nowych transakcji
   * po zakończeniu transakcji z listy <END CHECKPOINT>

   Awaria w trakcie CHECKPOINTu, trzeba:
    * odtworzyć transakcje, które rozpoczęły się po <START CHECKPOINT>
    * wszystkie transakcje z listy przy <START CHECKPOINT>

   Awaria po <END CHECKPOINT>
    * tylko transakcje po <START CHECKPOINT>

  UNDO:
   * pewne transakcje które wyglądają jakby były zaitwerdzone mogą zostać wycofane
   * COMMIT dopiero po zapisaniu wszystkich danych na dysk
   * problem w przypadku odtwarzania backupu

  REDO:
   * wymaga modyfikowania ...

  Redo/undo logging:
   * rekord logu zawiera starą i nową wartość: <T, X, v, w>
   * rekord logu dla każdej operacji
   * zapisz log na dysk zanim bufor X zostanie zapisany na dysk
   * zapisz log po każdym <COMMIT T>

   * rolling back:
    - konstruuj listę zatwierdzonych transakcji -- S
    - jeśli transakcja nie jest na liście S wykonaj UNDO
   * rolling forward
    - wykonaj operację REDO dla transakcji z listy S

    ..........dbdump.................lastneededundo................checkpoint
    not needed             not needed                    not needed
     for media         for undo after                for redo after
      recovery         system failure                system failure

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% WYKLAD 25.11.2008
% ISOLATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Najprostsze rozwiazanie: seryjne wykonywanie transakcji
Trudniej: rownolegle (szybkosc)

Transakcja to:
 * I/O + CPU
 * typy: duzo krotkich transakcji lub "dlugie" + "krotkie" -- potrzebne rozwiazanie!

Integralność danych
\begin{itemize}
\item transakcja zapewnia integralność
\item seryjne transakcje -- nie ma problemu
\item równoległe transakcje -- problem
\end{itemize}

Problemy wynikające z równoczesnego dostępu:
\begin{itemize}
\item problem utraconej modyfikacji (lost update)
\item zależność od niezatwierdzonej wartości (dirty read, uncommited dependency)
\item niespójna analiza (inconsistent analysis, nonrepeatable read) -- transakcja dwukrotnie odczytuje
      tą samą jednostkę danych (wiersz tabeli) i dostaje różne dane (w międzyczasie była modyfikacja)
\item phantom read -- odczyt danych, które pojawiły się podczas transakcji (INSERT)
\end{itemize}

Zapewnienie wszystkich reguł jest \emph{bardzo} kosztowne i zazwyczaj są pewne odstępstwa.

Poziom izolacji -- pewne ustawienie, które definiuje jakie zapewniamy rozwiązania izolacji (trzeba
wybrać między kosztem obsługi a zapewnioną izolacją)

\begin{itemize}
\item transakcje to programy
\item możliwe różne uszeregowanie operacji
\item trudno analizować czy transakcje zależą od siebie czy nie
\item ograniczamy tą analizę do READ i WRITE
\end{itemize}

Przykład:
  T1:
    1. READ(A)
    2. A = A + 100
    3. WRITE(A)
    4. READ(B)
    5. B = B + 100
    6. WRITE(B)

  T2:
    1. READ(A)
    2. A = A * 2
    3. WRITE(A)
    4. READ(B)
    5. B = B * 2
    6. WRITE(B)

  CONSTRAINT A == B

  * transakcje wykonywane w kolejności T1, T2 -- zapewniony constraint
  * kolejność T2, T1 -- zapewniony constraint ale \emph{inny wynik}
  * T1.1, T1.2, T1.3, T2.1, T2.2, T2.3, T1.4, T1.5, T1.6, T2.4, T2.5, T2.6 -- wynik okej
  * T1.{1-3}, T2.{1-6}, T1.{4-6} -- nie spełniona integralność
  * to co powyzej ale mnozenie razy 1 -- spełniona integralność

  Które są dobre? (niezależnie od danych wejściowych i operacji w transakcji)

Koniec przykładu.

Rozwiązywanie problemu izolacji:

1. Wyróżniamy transkacje READ i WRITE w transakcji (szeregowalność konfliktów)
\begin{itemize}
\item jeżeli instrukcje odnoszą się do różnych danych to można je zamienić miejscami
\item jeżeli odnoszą się do tych samych danych i przynajmniej jedna jest WRITEt to jest \emph{konflikt}
\end{itemize}

Uszeregowanie S:
 * I_i, I_j -- dwie kolejne instrukcje
 * jeśli nie są w konflikcie to można je zamienić
 * dostajemy uszregowanie S'
 * S i S' są równoważne
 * S' jest serializowalny, szeregowalny -- daje te same wyniki
Definicja: plany są równoważne ?
Definicja: plan szeregowalny: plan jest szregowalny ze wzgłedy na konflikt jesśli jest on zgodny z planem
seryjnym (sekwencyjnym)

Plan może być przekształcony do uszeregowania sekwencyjnego <T1, T2> przez serię zamian instrukcji, które
nie są w konflikcie.

Istnieją plany, których nie da się uzyskać tą metodą a dają taki sam wynik (ale znalezienie ich jest
kosztowne)

2. Odniesienie do READ/WRITE -- szeregowalność widoków)
 * view serializability
 * view equivalent
Reguły:
 * dla każdej danej Q jeśli Ti czyta początkową wartość w planie S to musi także czytać w S'
 * dla każdej danej Q jeśli Ti wykonuje READ(Q) w S i wartość Q jest ``wyprodukowana`` przez Tj
   to w  S' musi być tak samo
 * dla każdej danej Q jesśli Ti wykonuje końcowy zapis WRITE(Q) to S' także musi go wykonywać
   (zapewnia takie same wyniki planów)

 * szeregowanie konfliktów zawiera się w szeregowaniu widoków (ale nie na odwrót)

    T2    |   T4     |   T6
 ---------+----------+---------
  READ(Q) |          |
          | WRITE(Q) |
  WRITE(Q)|          |
          |          | WRITE(Q)


AWARIE TRANSAKCJI

 * jeżeli awarii uległa Ti to trzeba ją wycofać i wszystkie te które są od niej zależne
   (takie które przeczytały to co zapisała Ti)
 * musimy limitować uszeregowania do takich, które pozwalają na wycofanie transakcji zależnych

 T8      |     T9
 --------+--------
 READ(A) |
 WRITE(A)|
         | READ(A)
 READ(B) |

 * Jeśli COMMIT<T9> byl zaraz po READ(A) to taka sytuacja powoduje brak możliwości odtworzenia
   (nonrecoverable)
 * uszeregowania odtwarzalne (recoverable) -- jeśli transakcja Tj czyta zapisane Ti to COMMIT Tj
   musi nastąpić \emph{po} COMMIT Ti

3. Uszeregowania ``wolne`` od kaskadowego wycofywania (``cascadeless schedule``)
Jeżeli Tj czyta dane zapisane przez Ti to Ti musi się zakończyć zanim Tj przeczyta dane
Każde uszeregowanie ``cascadeless`` jest ``recoverable``

Kaskadowe wycofywanie transakcji
  * T10, T11, T12, jeśli T10 padnie to trzeba wycofać T11 i T12

Rozwiązania:
 * można analizować czy uszeregowanie spełnia kryteria:
   * ale ``conflict`` zlożoność takiej analizy $n^2$
   * view $2^n$

Protokoły zapewniające pożądane cechy uszregeowania:
 * wiele
 * m.in. ``lock based protocols`` -- blokady, najpopularniejsze

Poziomy izolacji:
 * serializable (default)
 * repetable read
 * read commited (most often)
 * read uncommited
 * SET ISOLATION LEVEL <typ>

Zerknąć na http://www.postgresql.org/docs/8.3/static/transaction-iso.html#MVCC-ISOLEVEL-TABLE

Szeregowalność według jakiego ``punktu``?
\begin{itemize}
\item dowolny
\item moment COMMIT (do tego dążymy)
\item moment rozpoczęcia
\end{itemize}

Metody pozwalające zarządzać równoczesnym dostępem (protokoły)
 * \ac{2PL}
  * strict \ac{2PL}
  * rigorous \ac{2PL}
 * tree
 * timestamp
 * validation
 * multiversion
  * timestamp
  * two-phase locking

\end{comment}
\section{Akronimy}
\begin{acronym}
  \acro{2PL}{Two-Phase Locking}
  \acro{ACID}{Atomicity, Consistency, Isolation, Durability}
  \acro{ISAM}{Index Sequential Access Method}
  \acro{MTTF}{Mean Time To Failure}
  \acro{RAID}{Redundant Array of Independent Disks}
  \acro{SQL}{Structured Query Language}
  \acro{SZBD}{System Zarządzania Bazą Danych}
\end{acronym}
\end{document}
